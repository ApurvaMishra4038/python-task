{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7vaqm/prhn8p3n++/KAGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApurvaMishra4038/python-task/blob/main/python_scrape_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " we have scrape all products from this URL:\n",
        "https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2\n",
        "C283&ref=sr_pg_1\n",
        "Need to scrape atleast 20 pages of product listing pages\n",
        "Items to scrape\n",
        "• Product URL\n",
        "• Product Name\n",
        "• Product Price\n",
        "• Rating\n",
        "• Number of reviews"
      ],
      "metadata": {
        "id": "j3MK54--2Fx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "base_url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_{}\"\n",
        "num_pages = 20\n",
        "\n",
        "csv_file = open(\"amazon_products.csv\", mode=\"w\", newline='', encoding='utf-8')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['Product URL', 'Product Name', 'Product Price', 'Rating', 'Number of Reviews'])\n",
        "\n",
        "for page in range(1, num_pages + 1):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    products = soup.find_all(\"div\", class_=\"s-result-item\")\n",
        "\n",
        "    for product in products:\n",
        "        product_url = product.find(\"a\", class_=\"a-link-normal\")\n",
        "        if product_url:\n",
        "            product_url = product_url.get(\"href\")\n",
        "\n",
        "        product_name = product.find(\"span\", class_=\"a-text-normal\")\n",
        "        if product_name:\n",
        "            product_name = product_name.get_text(strip=True)\n",
        "\n",
        "        product_price = product.find(\"span\", class_=\"a-offscreen\")\n",
        "        if product_price:\n",
        "            product_price = product_price.get_text(strip=True)\n",
        "        else:\n",
        "            product_price = \"Not available\"\n",
        "\n",
        "        rating = product.find(\"span\", class_=\"a-icon-alt\")\n",
        "        if rating:\n",
        "            rating = rating.get_text(strip=True)\n",
        "        else:\n",
        "            rating = \"Not rated\"\n",
        "\n",
        "        num_reviews = product.find(\"span\", class_=\"a-size-base\")\n",
        "        if num_reviews:\n",
        "            num_reviews = num_reviews.get_text(strip=True)\n",
        "        else:\n",
        "            num_reviews = \"0\"\n",
        "\n",
        "        csv_writer.writerow([product_url, product_name, product_price, rating, num_reviews])\n",
        "\n",
        "csv_file.close()\n"
      ],
      "metadata": {
        "id": "sOpzoaYkzxTz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the Product URL received in the above case, hit each URL, and add below items:\n",
        "• Description\n",
        "• ASIN\n",
        "• Product Description\n",
        "• Manufacturer\n",
        "and store the output data in the csv file.."
      ],
      "metadata": {
        "id": "5Kns0NjL2kTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "base_url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_{}\"\n",
        "num_pages = 20\n",
        "\n",
        "csv_file = open(\"amazon_products.csv\", mode=\"w\", newline='', encoding='utf-8')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['Product URL', 'Product Name', 'Product Price', 'Rating', 'Number of Reviews', 'ASIN', 'Product Description', 'Manufacturer'])\n",
        "\n",
        "for page in range(1, num_pages + 1):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    products = soup.find_all(\"div\", class_=\"s-result-item\")\n",
        "\n",
        "    for product in products:\n",
        "        product_url = product.find(\"a\", class_=\"a-link-normal\")\n",
        "        if product_url:\n",
        "            product_url = \"https://www.amazon.in\" + product_url.get(\"href\")\n",
        "            product_response = requests.get(product_url)\n",
        "            product_soup = BeautifulSoup(product_response.text, 'html.parser')\n",
        "\n",
        "            asin_tag = product_soup.find(\"th\", string=\"ASIN\")\n",
        "            if asin_tag:\n",
        "                asin = asin_tag.find_next(\"td\").get_text(strip=True)\n",
        "            else:\n",
        "                asin = \"Not available\"\n",
        "\n",
        "            product_description_tag = product_soup.find(\"div\", id=\"productDescription\")\n",
        "            if product_description_tag:\n",
        "                product_description = product_description_tag.get_text(strip=True)\n",
        "            else:\n",
        "                product_description = \"Not available\"\n",
        "\n",
        "            manufacturer_tag = product_soup.find(\"a\", {\"id\": \"bylineInfo\"})\n",
        "            if manufacturer_tag:\n",
        "                manufacturer = manufacturer_tag.get_text(strip=True)\n",
        "            else:\n",
        "                manufacturer = \"Not available\"\n",
        "\n",
        "            product_name = product.find(\"span\", class_=\"a-text-normal\")\n",
        "            if product_name:\n",
        "                product_name = product_name.get_text(strip=True)\n",
        "\n",
        "            product_price = product.find(\"span\", class_=\"a-offscreen\")\n",
        "            if product_price:\n",
        "                product_price = product_price.get_text(strip=True)\n",
        "            else:\n",
        "                product_price = \"Not available\"\n",
        "\n",
        "            rating = product.find(\"span\", class_=\"a-icon-alt\")\n",
        "            if rating:\n",
        "                rating = rating.get_text(strip=True)\n",
        "            else:\n",
        "                rating = \"Not rated\"\n",
        "\n",
        "            num_reviews = product.find(\"span\", class_=\"a-size-base\")\n",
        "            if num_reviews:\n",
        "                num_reviews = num_reviews.get_text(strip=True)\n",
        "            else:\n",
        "                num_reviews = \"0\"\n",
        "\n",
        "            csv_writer.writerow([product_url, product_name, product_price, rating, num_reviews, asin, product_description, manufacturer])\n",
        "\n",
        "csv_file.close()\n"
      ],
      "metadata": {
        "id": "S-vV80he1TIN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2n4iGsUL1-mX"
      }
    }
  ]
}